{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4RiW7Vm2G5F"
   },
   "outputs": [],
   "source": [
    "##remember to change Runtime type to GPU\n",
    "from google.colab import drive ## give permission to colab to mount to Google Drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFwiv6gK2Rrl"
   },
   "outputs": [],
   "source": [
    "%cd /gdrive/My\\ Drive/segmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "## please specify your wanted batch size here\n",
    "batch_size = 16 # if the RAM is keeps getting OOM, then please reduce the training batch_size\n",
    "num_classes=7\n",
    "image_size = 480*640\n",
    "\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'rgb': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    'x': tf.io.FixedLenFeature([], tf.string),\n",
    "    'y': tf.io.FixedLenFeature([], tf.string),\n",
    "    'z': tf.io.FixedLenFeature([], tf.string),\n",
    "    'weight': tf.io.FixedLenFeature([num_classes],tf.float32),\n",
    "}\n",
    "\n",
    "## flip the image horizontally\n",
    "def flip(image):\n",
    "    return tf.image.flip_left_right(image)\n",
    "\n",
    "def subtract(image):\n",
    "    return tf.math.subtract(tf.ones(tf.shape(image))*255,image)\n",
    "\n",
    "#to rescale image back to [0,1] range\n",
    "def rescale(x):\n",
    "    x = tf.cast(x,tf.float32)\n",
    "    max_val = tf.reduce_max(x)\n",
    "    min_val = tf.reduce_min(x)\n",
    "    return (x-min_val)/(max_val-min_val+1e-7)\n",
    "\n",
    "##crop the image\n",
    "def crop(img,height,width,x1,y1):\n",
    "    img = img[y1:y1+height, x1:x1+width,:]\n",
    "    return img\n",
    "\n",
    "#blur the image by sliding a Gaussian kernel accross it\n",
    "def gaussian_blur(img, kernel_size=7, sigma=5):\n",
    "    def gauss_kernel(channels, kernel_size, sigma):\n",
    "        \n",
    "        ax = tf.range(-tf.cast(tf.math.floordiv(kernel_size,2),tf.int32) + 1, \n",
    "                      tf.cast(tf.math.floordiv(kernel_size,2),tf.int32) + 1)  \n",
    "           \n",
    "        xx, yy = tf.meshgrid(ax, ax)\n",
    "        yy = tf.cast(yy,tf.int32)\n",
    "        kernel = tf.exp(-(tf.cast(xx ** 2,tf.float32) + tf.cast(yy ** 2,tf.float32)) / (2 * sigma ** 2))\n",
    "        kernel = kernel / tf.reduce_sum(kernel)\n",
    "        kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])\n",
    "        return kernel\n",
    "\n",
    "    img = tf.cast(tf.expand_dims(img,axis=0),tf.float32)\n",
    "    gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)\n",
    "    gaussian_kernel = gaussian_kernel[..., tf.newaxis]\n",
    "    gaussian_kernel = tf.cast(gaussian_kernel,tf.float32)\n",
    "    \n",
    "    img = tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1],\n",
    "                                  padding='SAME', data_format='NHWC')\n",
    "    img = tf.cast(tf.squeeze(img),tf.float32)\n",
    "\n",
    "    return img\n",
    "    \n",
    "#parse function for training data\n",
    "def train_parse(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    data = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    rgb = tf.image.decode_jpeg(data['rgb'])\n",
    "    label = tf.image.decode_png(data['label'],dtype=tf.uint8)\n",
    "    x = tf.image.decode_jpeg(data['x'])\n",
    "    y = tf.image.decode_jpeg(data['y'])\n",
    "    z = tf.image.decode_jpeg(data['z'])\n",
    "    weight = data['weight']\n",
    "    \n",
    "    ##frauas image's resolution are 480x640\n",
    "    rgb = tf.reshape(rgb,(480,640,3))\n",
    "    label = tf.reshape(label,(480,640,1))\n",
    "    x = tf.reshape(x,(480,640,1))\n",
    "    y = tf.reshape(y,(480,640,1))\n",
    "    z = tf.reshape(z,(480,640,1))\n",
    "    weight = tf.reshape(weight,[num_classes,])\n",
    "\n",
    "    ##generate random crop coordinates\n",
    "    fraction = tf.random.uniform([],0.7,1.0)\n",
    "    height = tf.cast(480*fraction,tf.int32)\n",
    "    width = tf.cast(640*fraction,tf.int32)\n",
    "    y1 = tf.random.uniform([],0,481-height,dtype=tf.int32)\n",
    "    x1 = tf.random.uniform([],0,641-width,dtype=tf.int32)\n",
    "\n",
    "    ##crop out the patch\n",
    "    rgb = crop(rgb,height,width,x1,y1)\n",
    "    x = crop(x,height,width,x1,y1)\n",
    "    y = crop(y,height,width,x1,y1)\n",
    "    z = crop(z,height,width,x1,y1)\n",
    "    label = crop(label,height,width,x1,y1)\n",
    "\n",
    "    rgb = tf.cast(rgb,tf.float32)\n",
    "    label = tf.cast(label,tf.float32)\n",
    "    x = tf.cast(x,tf.float32)\n",
    "    y = tf.cast(y,tf.float32)\n",
    "    z = tf.cast(z,tf.float32)\n",
    "\n",
    "    ##random flipping\n",
    "    a = tf.random.uniform([],0.0,1.0)\n",
    "    rgb = tf.cond(tf.math.greater(a,0.5),lambda: flip(rgb), lambda : rgb)\n",
    "    x = tf.cond(tf.math.greater(a,0.5),lambda: flip(x), lambda : x)\n",
    "    y = tf.cond(tf.math.greater(a,0.5),lambda: flip(y), lambda : y)\n",
    "    z = tf.cond(tf.math.greater(a,0.5),lambda: flip(z), lambda : z)\n",
    "    label = tf.cond(tf.math.greater(a,0.5),lambda: flip(label), lambda : label)\n",
    "    x = tf.cond(tf.math.greater(a,0.5),lambda: subtract(x), lambda : x)\n",
    "\n",
    "    ## adding random gaussian noises to points cloud\n",
    "    noise_x = tf.random.normal(tf.shape(x), 0, 5)\n",
    "    noise_y = tf.random.uniform(tf.shape(y), 0, 5)\n",
    "    noise_z = tf.random.uniform(tf.shape(z), 0, 5)\n",
    "    x = x+noise_x\n",
    "    y = y+noise_y\n",
    "    z = z+noise_z\n",
    "   \n",
    "   ## data augmentation\n",
    "    saturation = tf.random.uniform([],0.5,3)\n",
    "    contrast = tf.random.uniform([],0.5,2.5)\n",
    "    brightness = tf.random.uniform([],-0.2,0.2)\n",
    "    hue = tf.random.uniform([],-0.9,0.9)\n",
    "    kernel_size = tf.random.uniform([],1,2,dtype=tf.int32)*2+1\n",
    "\n",
    "    saturation = tf.squeeze(saturation)\n",
    "    contrast = tf.squeeze(contrast)\n",
    "    brightness = tf.squeeze(brightness)\n",
    "    hue = tf.squeeze(hue)\n",
    "\n",
    "    rgb = tf.image.adjust_brightness(rgb, brightness)\n",
    "    rgb = tf.image.adjust_saturation(rgb, saturation)\n",
    "    rgb = tf.image.adjust_contrast(rgb,contrast)\n",
    "    blur_prob = tf.random.uniform([],0.0,0.7)\n",
    "    rgb = tf.cond(tf.math.greater(blur_prob,0.5),lambda: gaussian_blur(rgb, kernel_size=kernel_size), lambda : rgb)\n",
    "    \n",
    "    ## creating penalizing weights (optional, might comment out)\n",
    "    weight = tf.reshape(weight,(1,1,num_classes))\n",
    "    label1 = tf.one_hot(tf.cast(label,tf.uint8),num_classes)\n",
    "    label1 = tf.squeeze(label1)\n",
    "    weight = tf.tile(weight,(tf.shape(x)[0],tf.shape(x)[1],1))\n",
    "    weight = tf.math.multiply(weight,label1)\n",
    "    weight = tf.reduce_sum(weight,axis=-1)\n",
    "    weight = tf.reshape(weight,(tf.shape(x)[0],tf.shape(x)[1],1))\n",
    "\n",
    "    rgb = rgb/255\n",
    "    x = rescale(x)\n",
    "    y = rescale(y)\n",
    "    z = rescale(z)\n",
    "\n",
    "    imgs = tf.concat([rgb,x,y,z],axis=-1)\n",
    "    imgs = tf.image.resize(imgs,(480,640))\n",
    "\n",
    "    label= tf.image.resize(label,(480,640))\n",
    "    label = tf.cast(tf.math.round(label),tf.float32)\n",
    "    weight = tf.image.resize(weight,(480,640))\n",
    "    labels = tf.concat([label,weight],axis=-1)\n",
    "\n",
    "    return imgs,labels\n",
    "\n",
    "##parsing function for validation set\n",
    "def val_parse(example_proto):\n",
    "    data = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    rgb = tf.image.decode_jpeg(data['rgb'])\n",
    "    label = tf.image.decode_png(data['label'],dtype=tf.uint8)\n",
    "    x = tf.image.decode_jpeg(data['x'])\n",
    "    y = tf.image.decode_jpeg(data['y'])\n",
    "    z = tf.image.decode_jpeg(data['z'])\n",
    "    weight = data['weight']\n",
    "    \n",
    "    rgb = tf.reshape(rgb,(480,640,3))\n",
    "    label = tf.reshape(label,(480,640,1))\n",
    "    x = tf.reshape(x,(480,640,1))\n",
    "    y = tf.reshape(y,(480,640,1))\n",
    "    z = tf.reshape(z,(480,640,1))\n",
    "    weight = tf.reshape(weight,[num_classes,])\n",
    "\n",
    "    weight = tf.reshape(weight,(1,1,num_classes))\n",
    "    label1 = tf.one_hot(tf.cast(label,tf.uint8),num_classes)\n",
    "    label1 = tf.squeeze(label1)\n",
    "    weight = tf.tile(weight,(tf.shape(x)[0],tf.shape(x)[1],1))\n",
    "    weight = tf.math.multiply(weight,label1)\n",
    "    weight = tf.reduce_sum(weight,axis=-1)\n",
    "    weight = tf.reshape(weight,(tf.shape(x)[0],tf.shape(x)[1],1))\n",
    "\n",
    "    rgb = tf.cast(rgb,tf.float32)\n",
    "    label = tf.cast(label,tf.float32)\n",
    "    x = tf.cast(x,tf.float32)\n",
    "    y = tf.cast(y,tf.float32)\n",
    "    z = tf.cast(z,tf.float32)\n",
    "\n",
    "    rgb = rgb/255\n",
    "    x = rescale(x)\n",
    "    y = rescale(y)\n",
    "    z = rescale(z)\n",
    "\n",
    "    imgs = tf.concat([rgb,x,y,z],axis=-1)\n",
    "    imgs = tf.image.resize(imgs,(480,640))\n",
    "\n",
    "    label= tf.image.resize(label,(480,640))\n",
    "    label = tf.cast(tf.math.round(label),tf.float32)\n",
    "    weight = tf.image.resize(weight,(480,640))\n",
    "    labels = tf.concat([label,weight],axis=-1)\n",
    "    \n",
    "    return imgs,labels\n",
    "\n",
    "\n",
    "##remember to upload your tfrecords onto google drive\n",
    "train = tf.data.TFRecordDataset('train_custom.tfrecords').map(train_parse,num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(400).batch(batch_size).prefetch(100).repeat()\n",
    "val = tf.data.TFRecordDataset('val_custom.tfrecords').map(val_parse,num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().batch(1).prefetch(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1xqktpm3_Zd"
   },
   "outputs": [],
   "source": [
    "%cd /gdrive/My\\ Drive/segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "l2=1e-4\n",
    "dp=0.2\n",
    "\n",
    "## toggle this if you want to train from scratch (without loading weights trained on 7class frauas dataset)\n",
    "train_from_scratch = False \n",
    "\n",
    "##toggle these options for resume your previous training process (e.g. your session timeout or you restarted the kernel .....,)\n",
    "##Don't toggle these option if you want to train from the weights pretrained on SceneNet. \n",
    "continue_training = False\n",
    "if continue_training:\n",
    "    starting_epoch = 0\n",
    "    checkpoint_path = '' ## put the path of best checkpoint in the folder ./weights_custom/ here\n",
    "\n",
    "## please change these options to True to unfreeze the encoders when the model no longer improves its accuracy\n",
    "encoder_trainable_rgb=False \n",
    "encoder_trainable_depth = False \n",
    "\n",
    "## unfreeze encoders if train from scratch\n",
    "if train_from_scratch:\n",
    "    encoder_trainable_rgb=True \n",
    "    encoder_trainable_depth = True \n",
    "\n",
    "print('Users training config: ')\n",
    "print('Train from scratch: ', train_from_scratch)\n",
    "print('Continue training: ', continue_training)\n",
    "print('Train RGB encoders: ', encoder_trainable_rgb)\n",
    "print('Train Depth encoders: ', encoder_trainable_depth)\n",
    "\n",
    "if continue_training:\n",
    "    if checkpoint_path == '':\n",
    "        print('user has not specified previous checkpoint path')\n",
    "    else:\n",
    "        print('weights will be restored from this checkpoint: ', checkpoint_path)\n",
    "\n",
    "if (not continue_training) and (not train_from_scratch):\n",
    "    print('Weights will be loaded from SceneNet checkpoint')\n",
    "\n",
    "\n",
    "def get_link(layer, base_ch, growth_rate, grmul):\n",
    "    if layer == 0:\n",
    "        return base_ch, 0, []\n",
    "    out_channels = growth_rate\n",
    "    link = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        dv = 2 ** i\n",
    "        if layer % dv == 0:\n",
    "            k = layer - dv\n",
    "            link.append(k)\n",
    "            if i > 0:\n",
    "                out_channels *= grmul\n",
    "    \n",
    "    out_channels = int(int(out_channels + 1) / 2) * 2\n",
    "    \n",
    "    return out_channels, link\n",
    "\n",
    "def conv(x, depth, kernel_size=3, strides=1, padding = 'same',trainable=True):\n",
    "    return tf.keras.layers.Conv2D(depth, (kernel_size,kernel_size), (strides,strides), padding= padding,\n",
    "                                  kernel_initializer = tf.initializers.he_uniform(seed = 1),kernel_regularizer=tf.keras.regularizers.L2(l2),\n",
    "                                  trainable=trainable)(x)\n",
    "\n",
    "def batch_norm(x, trainable=True):\n",
    "    return tf.keras.layers.BatchNormalization(fused=True,trainable=trainable)(x)\n",
    "\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def resize(x, size):\n",
    "    return tf.image.resize(x, size)\n",
    "\n",
    "def drop_out(x):\n",
    "    return tf.keras.layers.Dropout(dp)(x)\n",
    "\n",
    "def avg_pool(x, pool_size = 2, strides = 2):\n",
    "    return tf.keras.layers.AveragePooling2D(pool_size, strides, padding = 'same')(x)\n",
    "\n",
    "def conv_layer(x, depth, kernel_size=3, strides=1,trainable=True,dropout=True):\n",
    "    x = conv(x, depth = depth, kernel_size=kernel_size, strides=strides,trainable=trainable)\n",
    "    x = batch_norm(x)\n",
    "    x = relu(x)\n",
    "    if dropout:\n",
    "        x = drop_out(x)   \n",
    "    return x\n",
    "\n",
    "def hardblock(x, in_channels, growth_rate, grmul, n_layers,trainable=True,dropout=True):\n",
    "    layers = [x]\n",
    "    out_layers = []\n",
    "    out_channels = 0\n",
    "    \n",
    "    for i in range(n_layers):    \n",
    "        links = []\n",
    "        out_ch, link = get_link(i+1, in_channels, growth_rate, grmul)\n",
    "    \n",
    "        for i in link:\n",
    "            links.append(layers[i])\n",
    "\n",
    "        x = tf.concat(links, axis = -1)\n",
    "        layers.append(conv_layer(x, out_ch,trainable=trainable,dropout=dropout))\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        if (i == len(layers)-1) or (i%2 == 1):\n",
    "            out_layers.append(layers[i])  \n",
    "    x = tf.concat(out_layers, axis = -1)\n",
    "    return x\n",
    "\n",
    "def transition_up(x, skip_connection):\n",
    "    x = resize(x, (tf.shape(skip_connection)[1], tf.shape(skip_connection)[2]))\n",
    "    x = tf.concat([x, skip_connection], axis = -1)\n",
    "    return x\n",
    "\n",
    "def se_block(x,trainable=True):\n",
    "    num_reduced_filters = tf.cast(x.shape[-1]*0.25,tf.int32).numpy()\n",
    "    se_tensor = layers.GlobalAveragePooling2D()(x)\n",
    "    se_tensor = layers.Reshape((1, 1, x.shape[-1]))(se_tensor)\n",
    "    se_tensor = layers.Conv2D(num_reduced_filters, 1, activation=tf.keras.activations.swish, padding='same',trainable=trainable,\n",
    "                              kernel_initializer = tf.initializers.he_uniform(seed = 1),kernel_regularizer=tf.keras.regularizers.L2(l2))(se_tensor)\n",
    "    se_tensor = layers.Conv2D(x.shape[-1],1,activation='sigmoid',padding='same',trainable=trainable,\n",
    "                              kernel_initializer = tf.initializers.he_uniform(seed = 1),kernel_regularizer=tf.keras.regularizers.L2(l2))(se_tensor)\n",
    "    x = layers.multiply([x, se_tensor])   \n",
    "    return x\n",
    "\n",
    "def hardnet(img): \n",
    "    depth = img[:,:,:,3:]\n",
    "    img = img[:,:,:,:3]\n",
    "    first_ch  = np.asarray([16,24,32,48])\n",
    "    depth_conv1 = np.asarray([64, 96, 160, 224, 320])\n",
    "    grmul = 1.7\n",
    "    gr       = np.asarray([  10,16,18,24,32])\n",
    "    n_layers = [4, 4, 8, 8, 8]\n",
    "    up_sample = np.asarray([126,238,374,534])\n",
    "    skip_connections = []\n",
    "    skip_connections_d = []\n",
    "    blks = len(n_layers)\n",
    "    \n",
    "    x = img\n",
    "    x = conv_layer(x, first_ch[0], strides = 2,trainable=encoder_trainable_rgb)\n",
    "    x = conv_layer(x, first_ch[1],trainable=encoder_trainable_rgb)\n",
    "    x = conv_layer(x, first_ch[2], strides = 2,trainable=encoder_trainable_rgb)\n",
    "    x = conv_layer(x, first_ch[3],trainable=encoder_trainable_rgb)\n",
    "\n",
    "    \n",
    "    x_d = depth\n",
    "    x_d = conv_layer(x_d, first_ch[0], strides = 2,trainable=encoder_trainable_depth)\n",
    "    x_d = conv_layer(x_d, first_ch[1],trainable=encoder_trainable_depth)\n",
    "    x_d = conv_layer(x_d, first_ch[2], strides = 2,trainable=encoder_trainable_depth)\n",
    "    x_d = conv_layer(x_d, first_ch[3],trainable=encoder_trainable_depth)\n",
    "    \n",
    "    ch = first_ch[3]\n",
    "    ch_d = first_ch[3]\n",
    "    for i in range(blks):\n",
    "        x = hardblock(x, ch, gr[i], grmul, n_layers[i],trainable=encoder_trainable_rgb)\n",
    "        x_d = hardblock(x_d, ch_d, gr[i], grmul, n_layers[i],trainable=encoder_trainable_depth)\n",
    "        \n",
    "        if i < blks-1:\n",
    "            skip_connections.append(tf.math.add(se_block(x,trainable=encoder_trainable_rgb),se_block(x_d,trainable=encoder_trainable_depth))) \n",
    "        x = conv_layer(x, x.shape[-1], kernel_size = 1,trainable=encoder_trainable_rgb)\n",
    "        x_d = conv_layer(x_d, x_d.shape[-1], kernel_size = 1,trainable=encoder_trainable_depth)\n",
    "        if i < blks-1:\n",
    "            x = avg_pool(x)\n",
    "            x_d = avg_pool(x_d)\n",
    "        ch = x.shape[-1]\n",
    "        ch_d = x_d.shape[-1]\n",
    "    \n",
    "    x = tf.math.add(se_block(x,trainable=encoder_trainable_rgb),se_block(x_d,trainable=encoder_trainable_depth))\n",
    "\n",
    "    n_blocks = blks-1\n",
    "    for i in range(n_blocks-1,-1,-1):\n",
    "        skip = skip_connections.pop()\n",
    "        x = transition_up(x, skip)\n",
    "\n",
    "        cur_channels_count = x.shape[-1]//2\n",
    "\n",
    "        x = conv_layer(x, cur_channels_count, kernel_size=1,dropout=False)\n",
    "        x = hardblock(x, cur_channels_count, gr[i], grmul, n_layers[i],dropout=False)\n",
    "\n",
    "    x_pre_conv = x\n",
    "    x = conv(x, depth = 7, kernel_size = 1)\n",
    "    \n",
    "    return x,x_pre_conv\n",
    "\n",
    "##first we have to built the model for scenenet to load the pretrained weights\n",
    "input = tf.keras.layers.Input(shape=(480,640,6))\n",
    "output1,output2 = hardnet(input)\n",
    "model = tf.keras.Model(inputs=input, outputs=[output1,output2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9x3N7I1c7KtV"
   },
   "outputs": [],
   "source": [
    "if (not train_from_scratch) and (not continue_training): \n",
    "    ## make sure you have uploaded the pretrained file weights_scenenet.h5 in the same folder with this script\n",
    "    model.load_weights('./weights_frauas_7classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UpcMtSH7puL"
   },
   "outputs": [],
   "source": [
    "##now we build the model for your custom dataset\n",
    "\n",
    "x = conv(output2,depth=num_classes,kernel_size=1)\n",
    "x = resize(x, (480,640))\n",
    "model = tf.keras.Model(inputs=input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7_cpiXj9zmF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class IoU(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"IoU\", **kwargs):\n",
    "        super(IoU, self).__init__(name=name, **kwargs)\n",
    "        self.m = tf.keras.metrics.MeanIoU(num_classes=num_classes)\n",
    "\n",
    "    def update_state(self, y_true, y_pred,sample_weight=None):\n",
    "        y_true = tf.expand_dims(y_true[:,:,:,0],axis=-1)\n",
    "        y_pred = tf.expand_dims(tf.math.argmax(y_pred,axis=-1),axis=-1)\n",
    "        self.m.update_state(y_true,y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        return self.m.result()\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.m.reset_states()\n",
    "\n",
    "def custom_loss(y_true,y_pred):\n",
    "    weight = y_true[:,:,:,1]\n",
    "    y_true = y_true[:,:,:,0]\n",
    "    weight = tf.expand_dims(weight,axis=-1)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    #loss1 = loss(y_true, y_pred, sample_weight=weight) #you may play around by uncommenting this\n",
    "    loss1 = loss(y_true, y_pred)\n",
    "\n",
    "    prob = tf.nn.softmax(y_pred)\n",
    "    y_true = tf.one_hot(tf.cast(y_true,tf.uint8),num_classes)\n",
    "    num = tf.reduce_sum(prob*y_true,axis=-1)\n",
    "    denom = tf.reduce_sum(prob + y_true-prob*y_true,axis=-1)+1e-7\n",
    "    loss2 = 1 - num/denom\n",
    "    loss2 = tf.expand_dims(loss2,axis=-1)\n",
    "    #loss2 = tf.reduce_mean(loss2*weight) #you may play around by uncommenting this\n",
    "    loss2 = tf.reduce_mean(loss2)\n",
    "\n",
    "    return loss1 + loss2\n",
    "\n",
    "##learning rate scheduler\n",
    "def scheduler(epoch):\n",
    "    epoch = epoch+starting_epoch\n",
    "    if 0.002/(0.2*epoch+1) > 0.0001:\n",
    "        return 0.002/(0.2*epoch+1)\n",
    "    else:\n",
    "        return 0.0001\n",
    "        \n",
    "##configure the model training and validation policies\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss=custom_loss, metrics=custom_metrics)\n",
    "\n",
    "##load previous model checkpoint if you want to resume training or if you want to unfreeze the encoders\n",
    "if continue_training: \n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "##save only best checkpoints\n",
    "checkpoint_filepath = './weight_custom/loss:{loss:.2f}_valIoU:{val_custom_metrics:.2f}.h5'\n",
    "cb_list = [tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,save_best_only = True, monitor = 'val_custom_metrics',verbose=1,mode='max'),\n",
    "        tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
    "model.fit(train,epochs = 1000,steps_per_epoch=1500,validation_data=val,callbacks=cb_list,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Tm74XLkKWAA"
   },
   "outputs": [],
   "source": [
    "best_model_path = '' #choose the best model in the folder weights_custom\n",
    "model.load_weights(best_model_path)\n",
    "vals = iter(val) ##create an iterator for the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLok2PfNKgRA"
   },
   "outputs": [],
   "source": [
    "## code snippet for visualization\n",
    "\n",
    "imgs,labels = next(vals)\n",
    "output = model.predict_on_batch(imgs)\n",
    "output = output[0]\n",
    "output = np.argmax(output,axis=-1)\n",
    "output = loutput\n",
    "label = labeller(labels[0,:,:,0])\n",
    "rgb = imgs[0,:,:,:3]\n",
    "def plotter(img):\n",
    "    plt.imshow(img)\n",
    "    if img.shape[-1]!=3:\n",
    "        plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "plotter(output)\n",
    "plotter(label)\n",
    "plotter(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV8gz2dCLilA"
   },
   "outputs": [],
   "source": [
    "## code snippet to calculate the model performance\n",
    "\n",
    "def numpy_metrics(y_pred, y_true, n_classes):\n",
    "    y_pred = np.argmax(y_pred, axis=-1).flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    I = np.zeros(n_classes)\n",
    "    U = np.zeros(n_classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        y_true_i = y_true == i\n",
    "        y_pred_i = y_pred == i\n",
    "\n",
    "        I[i] = np.sum(y_true_i & y_pred_i)\n",
    "        U[i] = np.sum((y_true_i | y_pred_i))\n",
    "\n",
    "    accuracy = np.sum(I) / image_size\n",
    "    return I, U, accuracy\n",
    "\n",
    "acc_tot = 0\n",
    "n_imgs = 0\n",
    "I_tot = 0\n",
    "U_tot = 0\n",
    "vals =iter(val)\n",
    "while 1:\n",
    "    try:\n",
    "        imgs,labels = next(vals)\n",
    "        output = model.predict_on_batch(imgs)\n",
    "        output = output[0]\n",
    "        gt = labels[0,:,:,0].numpy()\n",
    "        I, U, acc = numpy_metrics(output, gt, num_classes)\n",
    "        I_tot += I\n",
    "        U_tot += U\n",
    "        acc_tot += acc \n",
    "        n_imgs += 1\n",
    "    except:\n",
    "        print('finish')\n",
    "        break\n",
    "\n",
    "iou= np.mean(I_tot / (U_tot+1e-7))\n",
    "accuracy = acc_tot / n_imgs\n",
    "for label, jacc in zip(range(7), I_tot / U_tot):\n",
    "    print('class {} :\\t{:.4f}'.format(label, jacc)) ## please have a look at the mapping in the json_to_label file\n",
    "print ('Mean Jaccard', iou)\n",
    "print ('Mean accuracy', accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5aPVglqHmBdL4+0RS/GGM",
   "collapsed_sections": [],
   "name": "train_custom.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
